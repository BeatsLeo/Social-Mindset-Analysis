{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers.optimization import get_scheduler\n",
    "from transformers.data.data_collator import default_data_collator\n",
    "from datasets import load_dataset, load_from_disk, concatenate_datasets\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GPT2Model, AdamW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载编码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreTrainedTokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_len=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[24717, 649, 3200, 507, 422, 262, 21694, 4991], [3642, 1299, 645, 20868, 11, 691, 2248, 1850, 308, 3775]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "\n",
    "print(tokenizer)\n",
    "\n",
    "# 添加pad\n",
    "tokenizer.add_special_tokens({'pad_token': '<|endoftext|>'})\n",
    "\n",
    "# 编码试算\n",
    "tokenizer.batch_encode_plus([\n",
    "    'hide new secretions from the parental units',\n",
    "    'contains no wit, only labored gags'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (C:/Users/BeatsLeo/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee08f936c68b441a90daa9b6e92d05b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at C:/Users/BeatsLeo/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1\\cache-e7af3cac5f3bb93c.arrow and C:/Users/BeatsLeo/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1\\cache-477ff4d300ae4b97.arrow\n",
      "Loading cached shuffled indices for dataset at C:/Users/BeatsLeo/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1\\cache-1cc79241861da5a7.arrow\n",
      "Loading cached shuffled indices for dataset at C:/Users/BeatsLeo/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1\\cache-92ac5a1ec5c26bfa.arrow\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "dataset = load_dataset('imdb')\n",
    "\n",
    "# 重新切分数据集(先将train, test, unsupervised合并, 再划分)\n",
    "dataset = concatenate_datasets([dataset['train'], dataset['test'], dataset['unsupervised']])\n",
    "\n",
    "dataset = dataset.train_test_split(test_size=0.01, seed=0)\n",
    "\n",
    "# 采样, 数据量太大了跑不动\n",
    "dataset['train'] = dataset['train'].shuffle(0).select(range(80000))\n",
    "dataset['test'] = dataset['test'].shuffle(0).select(range(200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:/Users/BeatsLeo/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1\\cache-050b01d5730135f9_00000_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:/Users/BeatsLeo/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1\\cache-050b01d5730135f9_00001_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:/Users/BeatsLeo/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1\\cache-050b01d5730135f9_00002_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:/Users/BeatsLeo/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1\\cache-050b01d5730135f9_00003_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:/Users/BeatsLeo/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1\\cache-4da8f576c9de64f4_00000_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:/Users/BeatsLeo/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1\\cache-4da8f576c9de64f4_00001_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:/Users/BeatsLeo/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1\\cache-4da8f576c9de64f4_00002_of_00004.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:/Users/BeatsLeo/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1\\cache-4da8f576c9de64f4_00003_of_00004.arrow\n"
     ]
    }
   ],
   "source": [
    "def f(data, tokenizer):\n",
    "    # 移除<br/>\n",
    "    for i in range(len(data['text'])):\n",
    "        data['text'][i] = data['text'][i].replace('<br /><br />', ' ')\n",
    "    \n",
    "    data = tokenizer.batch_encode_plus(data['text'])\n",
    "\n",
    "    return data\n",
    "\n",
    "dataset = dataset.map(f,\n",
    "                      batched=True,\n",
    "                      num_proc=4,\n",
    "                      batch_size=1000,\n",
    "                      remove_columns=['text', 'label'],\n",
    "                      fn_kwargs={'tokenizer': tokenizer}\n",
    ")\n",
    "\n",
    "# 过滤掉太短的句子\n",
    "def f(data):\n",
    "    return [sum(i) >= 25 for i in data['attention_mask']]\n",
    "\n",
    "dataset = dataset.filter(f, batched=True, num_proc=4, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        "
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 44863\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 107\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(data):\n",
    "    block_size = 512\n",
    "\n",
    "    # 展平数据\n",
    "    input_ids = []\n",
    "    for i in data['input_ids']:\n",
    "        input_ids.extend(i)\n",
    "\n",
    "    # 切断数据(做成段(句子)(batch))\n",
    "    data = {'input_ids': [], 'attention_mask': []}\n",
    "    for i in range(len(input_ids) // block_size):\n",
    "        block = input_ids[i*block_size: (i+1)*block_size]\n",
    "        data['input_ids'].append(block)\n",
    "        data['attention_mask'].append([1] * block_size) # 全部参与attention计算\n",
    "\n",
    "    # 设置labels\n",
    "    data['labels'] = data['input_ids'].copy()\n",
    "\n",
    "    return data\n",
    "\n",
    "dataset = dataset.map(f, batched=True, batch_size=1000,num_proc=4)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11215,\n",
       " {'input_ids': tensor([[  340,   351,  6088,  ...,   966,   286,   852],\n",
       "          [  262,  1388,  3350,  ...,  4556, 13181,    11],\n",
       "          [  281,   555, 24194,  ...,   339,   468,  4753],\n",
       "          [  649, 12835,   706,  ...,    11, 27577,  6735]]),\n",
       "  'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          [1, 1, 1,  ..., 1, 1, 1]]),\n",
       "  'labels': tensor([[  340,   351,  6088,  ...,   966,   286,   852],\n",
       "          [  262,  1388,  3350,  ...,  4556, 13181,    11],\n",
       "          [  281,   555, 24194,  ...,   339,   468,  4753],\n",
       "          [  649, 12835,   706,  ...,    11, 27577,  6735]])})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset = dataset['train'], \n",
    "    batch_size = 4, \n",
    "    collate_fn = default_data_collator,\n",
    "    shuffle = True,\n",
    "    drop_last = True\n",
    ")\n",
    "\n",
    "for i, data in enumerate(loader):\n",
    "    break\n",
    "\n",
    "len(loader), data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义下游任务模型\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pretrained = GPT2Model.from_pretrained('gpt2')\n",
    "        self.fc = torch.nn.Linear(768, tokenizer.vocab_size, bias=False)\n",
    "\n",
    "        # 加载预训练模型\n",
    "        parameters = AutoModelForCausalLM.from_pretrained('gpt2')\n",
    "        self.fc.load_state_dict(parameters.lm_head.state_dict())\n",
    "\n",
    "        self.criterion =torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels):\n",
    "        logits = self.pretrained(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = logits.last_hidden_state\n",
    "        logits = self.fc(logits)\n",
    "\n",
    "        shift_logits = logits[:, :-1].flatten(end_dim=1)\n",
    "        shift_labels = labels[:, 1:].flatten()\n",
    "\n",
    "        loss = self.criterion(shift_logits, shift_labels)\n",
    "\n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'logits': logits\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型试算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16303.7184\n",
      "torch.Size([4, 512])\n",
      "torch.Size([2044])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(3.7133), torch.Size([4, 512, 50257]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model()\n",
    "\n",
    "# 统计参数量\n",
    "print(sum(i.numel() for i in model.parameters()) / 10000)   # numel : number of elements\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(**data)\n",
    "out['loss'], out['logits'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文本生成函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(text):\n",
    "\n",
    "    def generate_loop(data):\n",
    "        with torch.no_grad():\n",
    "            out = model(**data)\n",
    "        print(out['logits'].shape)\n",
    "        \n",
    "        # 取最后一个字\n",
    "        # [5, b, 50257]\n",
    "        out = out['logits']\n",
    "        # [5, 50257]\n",
    "        out = out[:, -1]\n",
    "\n",
    "        # 第50大的值, 以此为分界线, 小于该值的全部赋值为负无穷\n",
    "        # [5, 50257] -> [5, 50]\n",
    "        topk_value = torch.topk(out, 50).values\n",
    "        # [5, 50] -> [5] -> [5, 1]\n",
    "        topk_value = topk_value[:, -1].unsqueeze(dim=1)\n",
    "\n",
    "        # 赋值\n",
    "        # [5, 50257]\n",
    "        out = out.masked_fill(out < topk_value, -float('inf'))  # 类似与torch.where\n",
    "\n",
    "        # 根据概率采样, 无放回, 所以不可能重复\n",
    "        # [5, 50257] -> [5, 1]\n",
    "        out = out.softmax(dim=1)\n",
    "        out = out.multinomial(num_samples=1)    # 值就是采样权重(概率), replacement默认为False不放回, 返回该值的下标\n",
    "\n",
    "        data['input_ids'] = torch.cat([data['input_ids'], out], dim=1)\n",
    "        data['attention_mask'] = torch.ones_like(data['input_ids'])\n",
    "        data['labels'] = data['input_ids'].clone()\n",
    "\n",
    "        if(data['input_ids'].shape[1] >= 30):   # 大于max_length\n",
    "            return data\n",
    "        \n",
    "        return generate_loop(data)\n",
    "\n",
    "    # 重复5遍\n",
    "    data = tokenizer.batch_encode_plus([text] * 5, return_tensors = 'pt')\n",
    "    data['labels'] = data['input_ids'].clone()\n",
    "\n",
    "    data = generate_loop(data)\n",
    "\n",
    "    for i in range(5):\n",
    "        print(i, tokenizer.decode(data['input_ids'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[5239]]), 'attention_mask': tensor([[1]])}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate('I love this')\n",
    "data = tokenizer(['text'], return_tensors = 'pt')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    global model\n",
    "    device = 'cpu' if torch.cuda.is_available() else 'cpu'\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr = 2e-5)\n",
    "    scheduler = get_scheduler(name='linear',\n",
    "                              num_warmup_steps=0,\n",
    "                              num_training_steps=len(loader),\n",
    "                              optimizer=optimizer)\n",
    "    \n",
    "    model.train()\n",
    "    for i, data in enumerate(loader):\n",
    "        for k in data.keys():\n",
    "            data[k] = data[k].to(device)\n",
    "\n",
    "        out = model(**data)\n",
    "        loss = out['loss']\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) # 解决梯度爆炸\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        model.zero_grad()\n",
    "\n",
    "        if(i % 50 == 0):\n",
    "            labels = data['labels'][:, 1:]\n",
    "            out = out['logits'].argmax(dim=2)[:, :-1]\n",
    "\n",
    "            accuracy = (out == labels).sum().item() / labels.numel()\n",
    "\n",
    "            lr = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "\n",
    "            print(i, loss.item(), lr, accuracy)\n",
    "\n",
    "    model = model.to('cpu')\n",
    "\n",
    "train()\n",
    "torch.save(model, './models/en_gen.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load('models/en_gen.model')\n",
    "generate('I love this')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('beatsleo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 06:59:08) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16ea64f9ee948d927ad35fd9dd41586a042d593dc7bf73dbea6b47fb27e81f20"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

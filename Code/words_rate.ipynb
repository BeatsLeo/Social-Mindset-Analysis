{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import pandas\n",
    "from ltp import LTP\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取本地数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_data_sentences(path):    \n",
    "    data = json.load(open(path, \"r\", encoding=\"utf-8\"))\n",
    "    sentences = []\n",
    "    for key in data:\n",
    "        for d in data[key]:\n",
    "            # 帖子\n",
    "            sentence = d['post'].strip()\n",
    "            if(sentence != '' and sentence != 'None'):\n",
    "                sentences.append(sentence)\n",
    "            # 评论\n",
    "            for comment in d['comments']:\n",
    "                sentence = comment['content'].strip()\n",
    "                if(sentence != '' and sentence != 'None'):\n",
    "                    sentences.append(sentence)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "root = './rawdata/'\n",
    "sentences = []\n",
    "for p in os.listdir(root):\n",
    "    path = os.path.join(root, p)\n",
    "    sentences += get_raw_data_sentences(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 统计词频"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltp = LTP()\n",
    "if torch.cuda.is_available():\n",
    "    ltp.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "dataset = Dataset(sentences)\n",
    "loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=1024, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_words = []\n",
    "for inputs in tqdm(loader):\n",
    "    with torch.no_grad():\n",
    "        words = ltp.pipeline(inputs, tasks = [\"cws\", 'pos'], return_dict = False)\n",
    "    for w in zip(words[0], words[1]):\n",
    "        final_words += list(zip(w[0], w[1]))\n",
    "\n",
    "final_words = pandas.DataFrame(final_words)\n",
    "final_words = list(final_words.value_counts().items())\n",
    "\n",
    "# with open(\"./dataset/key_words/keywords1.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     for i in final_words:\n",
    "#         f.write(i[0][0] + ',' + i[0][1] + ',' + str(i[1]) + \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理关键词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载停用词\n",
    "with open('./dataset/key_words/stopwords/stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    stopwords = f.readlines()\n",
    "    stopwords = [w.strip() for w in stopwords]\n",
    "stopwords = set(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载关键词\n",
    "with open('./dataset/key_words/keywords.txt', 'r', encoding='utf-8') as f:\n",
    "    keywords = f.readlines()\n",
    "    keywords = [w.strip().split(',') for w in keywords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filted = filter(lambda x: (x[0] not in stopwords) and (x[1] in ['ns', 'n', 'nh', 'v']) and (len(x[0]) > 1), keywords)\n",
    "filted = list(filted)\n",
    "filted.sort(key=lambda x: int(x[2]), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4cf0f9d19f930c0d767c3f7baba24a6088a8d3b88d2ccda0ac2e69305189dcd3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

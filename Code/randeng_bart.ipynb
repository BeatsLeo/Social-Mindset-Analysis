{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from transformers import BartForConditionalGeneration, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if(torch.cuda.is_available()) else 'cpu'\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=BartForConditionalGeneration.from_pretrained('IDEA-CCNL/Randeng-BART-139M-SUMMARY')\n",
    "tokenizer=AutoTokenizer.from_pretrained('IDEA-CCNL/Randeng-BART-139M-SUMMARY')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 450295/450295 [00:00<00:00, 667048.85it/s]\n"
     ]
    }
   ],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        \"\"\"输入data格式:\n",
    "            [{'title': '</s>....', 'content': '......'}, {}, ..., {}]\n",
    "        \"\"\"\n",
    "        random.shuffle(data)\n",
    "        for i in tqdm(range(len(data))):\n",
    "            data[i]['title'] = '</s>' + data[i]['title'].replace('<s>', '').replace('</s>', '').strip()\n",
    "            data[i]['content'] = data[i]['content'].strip()\n",
    "        \n",
    "        data = data[:2000]\n",
    "        train_len = int(0.7 * len(data))\n",
    "        self.train_data = data[:train_len]\n",
    "        self.test_data = data[train_len:]\n",
    "        \n",
    "        self.train = True\n",
    "    \n",
    "    def __len__(self):\n",
    "        if(self.train):\n",
    "            return len(self.train_data)\n",
    "        else:\n",
    "            return len(self.test_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if(self.train):\n",
    "            return self.train_data[idx]\n",
    "        else:\n",
    "            return self.test_data[idx]\n",
    "        \n",
    "weibo = json.load(open(\"./dataset/text_summary/news_title/weibo_data.json\"))\n",
    "dataset = Dataset(weibo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    titles = [i['title'] for i in data]\n",
    "    contents = [i['content'] for i in data]\n",
    "    labels = [i['title'][4:] for i in data]\n",
    "    \n",
    "    decoder_input_ids = tokenizer.batch_encode_plus(titles, return_tensors='pt', return_attention_mask=False, padding=True, add_special_tokens=False)\n",
    "    contents = tokenizer.batch_encode_plus(contents, return_tensors=\"pt\", padding=True, add_special_tokens=True)\n",
    "    labels = tokenizer.batch_encode_plus(labels, return_tensors=\"pt\", padding=True, return_attention_mask=False, add_special_tokens=True)\n",
    "    \n",
    "    data = {}\n",
    "    data['input_ids'] = contents['input_ids'].to(device)\n",
    "    data['attention_mask'] = contents['attention_mask'].to(device)\n",
    "    data['decoder_input_ids'] = decoder_input_ids['input_ids'].to(device)\n",
    "    data['labels'] = labels['input_ids'].to(device)\n",
    "\n",
    "    return data\n",
    "\n",
    "loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                     batch_size=4,\n",
    "                                     collate_fn=collate_fn,\n",
    "                                     drop_last=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练进度-epoch: 1/5: 100%|███████| 350/350 [01:28<00:00,  3.94it/s, loss=1.7687]t/s]\n",
      "训练进度-epoch: 2/5: 100%|███████| 350/350 [01:18<00:00,  4.47it/s, loss=1.0384]t/s]\n",
      "训练进度-epoch: 3/5: 100%|███████| 350/350 [01:17<00:00,  4.50it/s, loss=0.5588]t/s]\n",
      "训练进度-epoch: 4/5: 100%|███████| 350/350 [01:17<00:00,  4.52it/s, loss=0.2603]t/s]\n",
      "训练进度-epoch: 5/5: 100%|███████| 350/350 [01:16<00:00,  4.57it/s, loss=0.1080]t/s]\n"
     ]
    }
   ],
   "source": [
    "def train(model, epoches, lr):\n",
    "    lens = len(loader)\n",
    "    model = model.to(device)\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    losses = torch.zeros((epoches, lens))\n",
    "    for i in range(epoches):\n",
    "        with tqdm(total=lens, ncols=80) as bar:\n",
    "            bar.set_description('训练进度-epoch: {}/{}'.format(i+1,epoches))\n",
    "            for n,d in enumerate(loader):\n",
    "                loss = model(**d)['loss']\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "                optim.zero_grad()\n",
    "                \n",
    "                losses[i,n] += loss.item()\n",
    "                bar.update(1)\n",
    "                \n",
    "            bar.set_postfix(loss = '{:.4f}'.format(losses[i].mean().item()))\n",
    "    \n",
    "    model.cpu()\n",
    "    return losses\n",
    "\n",
    "losses = train(model, 5, 2e-5)\n",
    "torch.save(model, './models/text_summary.model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(mdoel, text, max_new_tokens):\n",
    "    inputs = tokenizer.encode_plus(text, return_tensors='pt', add_special_tokens=False)\n",
    "    decoder_input_ids = tokenizer.encode_plus('</s>', return_tensors='pt', add_special_tokens=False)\n",
    "    for _ in range(max_new_tokens):\n",
    "        logits = model(**inputs, decoder_input_ids=decoder_input_ids['input_ids'])['logits']\n",
    "        # focus only the last time step\n",
    "        logits = logits[:, -1, :]   # becomes (B, C)\n",
    "        # apply softmax to get probabilities\n",
    "        probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "        # sample from the distribution\n",
    "        # idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
    "        idx_next = probs.argmax(dim=1, keepdim=True)  # (B, 1)\n",
    "        # append sampled index to the running squence\n",
    "        decoder_input_ids['input_ids'] = torch.cat((decoder_input_ids['input_ids'], idx_next), dim=1)\n",
    "    \n",
    "    text = tokenizer.decode(decoder_input_ids['input_ids'][0])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入模型\n",
    "model = torch.load('./models/text_summary.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "手动生成:  </s> 歼7战机年内全部退出空军作战序列</s><pad><pad><pad><pad>\n",
      "API生成:  歼7战机年内全部退出空军作战序列\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "text = '几百架歼7加速淘汰，今年可能全部退役随着航空工业实力的增强，中国空军也进入了快速换装期，有消息称，在年内，所有歼7战斗机就将退出现役。日前，有国内军事专家在央视节目中对外透露，在解放军所剩不多的歼7战斗机将在年内全部退出空军作战序列。如果真是如此的话，就代表着中国空军向着全面三代化，迈出了十分重要的一步。我们必须清楚地是，解放军加速退役这几百架歼7战机，并不是因为这些战机都已经到了服役年限，机体老化到无法继续执行任务，而是在中国航空工业实力提升，新锐战机产能达到一定水平后，为了强化部队战斗力作出的决定。要知道，虽然歼7在中国空军中的服役时间已经超过了50年，但这款飞机真正停产的时间还不到10年。中国空军现役的歼7基本也都是后期换装的型号，如果继续使用，还 能服役一段时间。此外，虽然是一款二代机，但歼7战机并不是一无是处，这位老将也有着自己的优点。' \n",
    "inputs = tokenizer.encode_plus(text, return_tensors='pt')\n",
    "model.cpu()\n",
    "print('手动生成: ', generate(model, text, max_new_tokens=15))\n",
    "model = model.to(device)\n",
    "print('API生成: ', tokenizer.decode(model.generate(inputs['input_ids'].to(device), max_length=128, do_sample=False)[0]).replace('</s>', '').strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beatsleo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16ea64f9ee948d927ad35fd9dd41586a042d593dc7bf73dbea6b47fb27e81f20"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

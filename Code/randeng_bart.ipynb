{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import openpyxl\n",
    "from tqdm import tqdm\n",
    "from rouge import Rouge\n",
    "from transformers import BartForConditionalGeneration, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if(torch.cuda.is_available()) else 'cpu'\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=BartForConditionalGeneration.from_pretrained('IDEA-CCNL/Randeng-BART-139M-SUMMARY')\n",
    "tokenizer=AutoTokenizer.from_pretrained('IDEA-CCNL/Randeng-BART-139M-SUMMARY')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, train_data, valid_data):\n",
    "        \"\"\"输入data格式:\n",
    "            [{'title': '</s>....', 'content': '......'}, {}, ..., {}]\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        for i in tqdm(range(len(train_data))):\n",
    "            train_data[i]['title'] = '</s>' + train_data[i]['title'].replace('<s>', '').replace('</s>', '').strip()\n",
    "            train_data[i]['content'] = train_data[i]['content'].strip()\n",
    "            \n",
    "        for i in tqdm(range(len(valid_data))):\n",
    "            valid_data[i]['title'] = '</s>' + valid_data[i]['title'].replace('<s>', '').replace('</s>', '').strip()\n",
    "            valid_data[i]['content'] = valid_data[i]['content'].strip()\n",
    "        \n",
    "        self.train_data = train_data\n",
    "        self.valid_data = valid_data\n",
    "        \n",
    "        self.train = True\n",
    "    \n",
    "    def __len__(self):\n",
    "        if(self.train):\n",
    "            return len(self.train_data)\n",
    "        else:\n",
    "            return len(self.valid_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if(self.train):\n",
    "            return self.train_data[idx]\n",
    "        else:\n",
    "            return self.valid_data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_from_self_summary(root):\n",
    "    train_data = []; valid_data = []\n",
    "    for p in os.listdir(root):\n",
    "        data = []\n",
    "        workbook = openpyxl.load_workbook(os.path.join(root,p))\n",
    "        table = workbook.active\n",
    "        rows = table.max_row\n",
    "        for row in tqdm(range(2, rows+1)):\n",
    "            d = {'title': table.cell(row, 2).value,\n",
    "                'content': table.cell(row, 1).value}\n",
    "            \n",
    "            if(d['content'] and d['title'] and d['title'].strip()!= ''):\n",
    "                data.append(d)\n",
    "                \n",
    "        # valid_data += data[:40]\n",
    "        train_data += data[:]\n",
    "        workbook.close()\n",
    "    return train_data, valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weibo = json.load(open(\"./dataset/text_summary/news_title/weibo_data.json\", encoding='utf-8'))\n",
    "# random.shuffle(weibo)\n",
    "train_data, valid_data = collect_from_self_summary('./dataset/text_summary/self_summary/labeled/')\n",
    "valid_data = weibo[:256]\n",
    "weibo = weibo[256:1024]\n",
    "dataset = Dataset(weibo + train_data, valid_data)\n",
    "print('微博: ', len(weibo), '自己打的: ', len(train_data), len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    titles = [i['title'] for i in data]\n",
    "    contents = [i['content'] for i in data]\n",
    "    labels = [i['title'][4:] for i in data]\n",
    "    \n",
    "    decoder_input_ids = tokenizer.batch_encode_plus(titles, return_tensors='pt', return_attention_mask=False, padding=True, add_special_tokens=False)\n",
    "    contents = tokenizer.batch_encode_plus(contents, return_tensors=\"pt\", padding=True, add_special_tokens=True, max_length=512, truncation=True)\n",
    "    labels = tokenizer.batch_encode_plus(labels, return_tensors=\"pt\", padding=True, return_attention_mask=False, add_special_tokens=True)\n",
    "    \n",
    "    data = {}\n",
    "    data['input_ids'] = contents['input_ids'].to(device)\n",
    "    data['attention_mask'] = contents['attention_mask'].to(device)\n",
    "    data['decoder_input_ids'] = decoder_input_ids['input_ids'].to(device)\n",
    "    data['labels'] = labels['input_ids'].to(device)\n",
    "\n",
    "    return data\n",
    "\n",
    "loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                     batch_size=2,\n",
    "                                     collate_fn=collate_fn,\n",
    "                                     drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge_score(model, dataset, loader):\n",
    "    dataset.train = False \n",
    "    model.eval()\n",
    "    rouge = Rouge()\n",
    "    preds = []; labels = []\n",
    "    # 生成验证集所有摘要\n",
    "    for d in loader:\n",
    "        lens = len(d['input_ids'])\n",
    "        for idx in range(lens):\n",
    "            inputs = d['input_ids'][idx,:][None]\n",
    "            pred = tokenizer.decode(model.generate(inputs, max_length=128, do_sample=False)[0]).replace('</s>', '').strip()\n",
    "            label = tokenizer.decode(d['labels'][idx,:]).replace('</s>', '').replace('<pad>', '').strip()\n",
    "            preds.append(pred)\n",
    "            labels.append(label)\n",
    "    # 计算rouge_score\n",
    "    rouge_score = rouge.get_scores(preds, labels)\n",
    "    res = {\n",
    "        'r-1': 0, 'r-2': 0, 'r-l': 0\n",
    "    }\n",
    "    for i in rouge_score:\n",
    "        res['r-1'] += i['rouge-1']['f']\n",
    "        res['r-2'] += i['rouge-2']['f']\n",
    "        res['r-l'] += i['rouge-l']['f']\n",
    "    res['r-1'] = round(res['r-1'] / len(rouge_score), 2)\n",
    "    res['r-2'] = round(res['r-2'] / len(rouge_score), 2)\n",
    "    res['r-l'] = round(res['r-l'] / len(rouge_score), 2)\n",
    "    \n",
    "    model.train()\n",
    "    dataset.train = True\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoches, lr):\n",
    "    lens = len(loader)\n",
    "    model = model.to(device)\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    losses = torch.zeros((epoches, lens))\n",
    "    for i in range(epoches):\n",
    "        with tqdm(total=lens, ncols=150) as bar:\n",
    "            bar.set_description('训练进度-epoch: {}/{}'.format(i+1,epoches))\n",
    "            for n,d in enumerate(loader):\n",
    "                loss = model(**d)['loss']\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "                optim.zero_grad()\n",
    "                 \n",
    "                losses[i,n] += loss.item()\n",
    "                bar.update(1)\n",
    "            # res = rouge_score(model, dataset, loader)\n",
    "            bar.set_postfix(loss = '{:.4f}'.format(losses[i].mean().item()))#, **res)\n",
    "    model.cpu()\n",
    "    return losses\n",
    "\n",
    "losses = train(model, 2, 2e-5)\n",
    "# model.cpu()\n",
    "torch.save(model, './models/text_summary2.model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(mdoel, text, max_new_tokens):\n",
    "    inputs = tokenizer.encode_plus(text, return_tensors='pt', add_special_tokens=False)\n",
    "    decoder_input_ids = tokenizer.encode_plus('</s>', return_tensors='pt', add_special_tokens=False)\n",
    "    for _ in range(max_new_tokens):\n",
    "        logits = model(**inputs, decoder_input_ids=decoder_input_ids['input_ids'])['logits']\n",
    "        # focus only the last time step\n",
    "        logits = logits[:, -1, :]   # becomes (B, C)\n",
    "        # apply softmax to get probabilities\n",
    "        probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "        # sample from the distribution\n",
    "        # idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
    "        idx_next = probs.argmax(dim=1, keepdim=True)  # (B, 1)\n",
    "        # append sampled index to the running squence\n",
    "        decoder_input_ids['input_ids'] = torch.cat((decoder_input_ids['input_ids'], idx_next), dim=1)\n",
    "    \n",
    "    text = tokenizer.decode(decoder_input_ids['input_ids'][0])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入模型\n",
    "model = torch.load('./models/text_summary.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "text = '一加2要来了,搭载了满血版的骁龙8处理器,跑分高达'\n",
    "inputs = tokenizer.encode_plus(text, return_tensors='pt')\n",
    "model.cpu()\n",
    "print('手动生成: ', generate(model, text, max_new_tokens=15))\n",
    "model = model.to(device)\n",
    "print('API生成: ', tokenizer.decode(model.generate(inputs['input_ids'].to(device), max_length=128, do_sample=False)[0]).replace('</s>', '').strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beatsleo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16ea64f9ee948d927ad35fd9dd41586a042d593dc7bf73dbea6b47fb27e81f20"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
